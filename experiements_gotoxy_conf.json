{
  "experiment1": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_32_32_tanh_lr0.001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [32, 32],
      "train.config.learning_rate": 1e-3
  },
  "experiment2": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_32_32_tanh_lr0.0005_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [32, 32],
      "train.config.learning_rate": 5e-4 
  },
  "experiment3": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_32_32_tanh_lr0.0001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [32, 32],
      "train.config.learning_rate": 1e-4 
  },
  "experiment4": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_64_64_tanh_lr0.001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [64, 64], 
      "train.config.learning_rate": 1e-3
  },
  "experiment5": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_64_64_tanh_lr0.0005_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [64, 64],
      "train.config.learning_rate": 5e-4 
  },
  "experiment6": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_64_64_tanh_lr0.0001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [64, 64],
      "train.config.learning_rate": 1e-4 
  },
  "experiment7": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_64_64_tanh_lr0.001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [128, 128], 
      "train.config.learning_rate": 1e-3
  },
  "experiment8": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_128_128_tanh_lr0.0005_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [128, 128],
      "train.config.learning_rate": 5e-4 
  },
  "experiment9": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_128_128_tanh_lr0.0001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [128, 128],
      "train.config.learning_rate": 1e-4 
  },
  "experiment10": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_256_tanh_lr0.001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 256], 
      "train.config.learning_rate": 1e-3
  },
  "experiment11": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_256_tanh_lr0.0005_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 256],
      "train.config.learning_rate": 5e-4 
  },
  "experiment12": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_256_tanh_lr0.0001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 256],
      "train.config.learning_rate": 1e-4 
  },
  "experiment13": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_128_64_tanh_lr0.001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 128, 64], 
      "train.config.learning_rate": 1e-3
  },
  "experiment14": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_128_64_tanh_lr0.0005_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 128, 64],
      "train.config.learning_rate": 5e-4 
  },
  "experiment15": {
      "task": "MFP2DGoToXY",
      "train": "MFP2DGoToXYPPO",
      "experiment": "MFP2DGoToXY_linear_256_128_64_tanh_lr0.0001_r1",
      "headless": "True",
      "task.env.learn.UseLinearRewards": 1,
      "task.env.learn.UseSquareRewards": 0,
      "task.env.learn.UseExponentialRewards": 0,
      "num_envs": "2048",
      "max_iterations": "4000",
      "train.params.network.mlp.units": [256, 128, 64],
      "train.config.learning_rate": 1e-4 
  }
}
