  0%|                                                                                                                                                                               | 0/16000 [00:00<?, ?it/s]/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/kit/python/lib/python3.7/site-packages/skrl/agents/torch/dqn/dqn.py:299: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  q_network_loss = F.mse_loss(q_values, target_values)
  0%|                                                                                                                                                                               | 0/16000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "dqn_floating_platform.py", line 97, in <module>
    trainer.train()
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/kit/python/lib/python3.7/site-packages/skrl/trainers/torch/sequential.py", line 75, in train
    self.single_agent_train()
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/kit/python/lib/python3.7/site-packages/skrl/trainers/torch/base.py", line 186, in single_agent_train
    self.agents.post_interaction(timestep=timestep, timesteps=self.timesteps)
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/kit/python/lib/python3.7/site-packages/skrl/agents/torch/dqn/dqn.py", line 265, in post_interaction
    self._update(timestep, timesteps)
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/kit/python/lib/python3.7/site-packages/skrl/agents/torch/dqn/dqn.py", line 303, in _update
    q_network_loss.backward()
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/extscache/omni.pip.torch-1_13_0-0.1.4+104.1.lx64/torch-1-13-0/torch/_tensor.py", line 488, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/matteo/.local/share/ov/pkg/isaac_sim-2022.2.0/extscache/omni.pip.torch-1_13_0-0.1.4+104.1.lx64/torch-1-13-0/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn